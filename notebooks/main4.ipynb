{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import KFold\n",
    "from albumentations import Compose, RandomResizedCrop, HorizontalFlip, Normalize, RandomRotate90, ShiftScaleRotate, CoarseDropout\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters and configurations\n",
    "config = {\n",
    "    \"base_dir\": \"/Users/saahil/Desktop/Coding_Projects/DL/MicroscopicFungi/archive-2\",\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 15,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"height\": 224,\n",
    "    \"width\": 224,\n",
    "    \"channels\": 3,\n",
    "    \"num_folds\": 5,\n",
    "    \"patience\": 10,\n",
    "    \"seed\": 40,\n",
    "    \"log_dir\": \"./logs\",\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = config[\"log_dir\"]\n",
    "\n",
    "# Clear the log directory\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(config[\"log_dir\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FungiDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, subset='train'):\n",
    "        self.root_dir = os.path.join(root_dir, subset)\n",
    "        self.transform = transform\n",
    "        self.classes = ['H1', 'H2', 'H3', 'H5', 'H6']  # List of class names\n",
    "        self.image_paths, self.labels = self._load_dataset()\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        image_paths, labels = [], []\n",
    "        for label, cls in enumerate(self.classes):\n",
    "            cls_dir = os.path.join(self.root_dir, cls)\n",
    "            if not os.path.exists(cls_dir):\n",
    "                raise FileNotFoundError(f\"Directory {cls_dir} does not exist.\")\n",
    "            for img_name in os.listdir(cls_dir):\n",
    "                img_path = os.path.join(cls_dir, img_name)\n",
    "                if os.path.isfile(img_path):\n",
    "                    image_paths.append(img_path)\n",
    "                    labels.append(label)\n",
    "        return image_paths, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))['image']\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(config[\"channels\"], 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(512 * (config[\"height\"] // 16) * (config[\"width\"] // 16), 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    return Compose([\n",
    "        RandomResizedCrop(config[\"height\"], config[\"width\"], scale=(0.8, 1.0)),\n",
    "        HorizontalFlip(),\n",
    "        RandomRotate90(),\n",
    "        ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30),\n",
    "        CoarseDropout(max_holes=8, max_height=32, max_width=32),\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, fold, epoch, best=False):\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    filename = f'checkpoint_fold{fold}_epoch{epoch}{\"_best\" if best else \"\"}.pth'\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for inputs, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = running_loss / len(dataloader.dataset)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def train_model():\n",
    "    dataset = FungiDataset(config[\"base_dir\"], transform=get_transforms(), subset='train')\n",
    "    num_classes = len(dataset.classes)\n",
    "    \n",
    "    # Compute class weights for handling class imbalance\n",
    "    class_weights = compute_class_weight('balanced', classes=np.arange(len(dataset.classes)), y=dataset.labels)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    # Use StratifiedKFold to ensure each fold has a similar class distribution\n",
    "    skf = StratifiedKFold(n_splits=config[\"num_folds\"], shuffle=True, random_state=config[\"seed\"])\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(np.arange(len(dataset)), dataset.labels), 1):\n",
    "\n",
    "        print(f\"Fold {fold}/{config['num_folds']}\")\n",
    "        \n",
    "        # Extract the labels for the train and validation indices\n",
    "        train_labels = np.array(dataset.labels)[train_idx]\n",
    "        val_labels = np.array(dataset.labels)[val_idx]\n",
    "        print(f\"Fold {fold} - Train Class Distribution: {np.bincount(train_labels)}\")\n",
    "        print(f\"Fold {fold} - Val Class Distribution: {np.bincount(val_labels)}\")\n",
    "\n",
    "        # Set up the data samplers and loaders\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        val_sampler = SubsetRandomSampler(val_idx)\n",
    "        train_loader = DataLoader(dataset, batch_size=config[\"batch_size\"], sampler=train_sampler)\n",
    "        val_loader = DataLoader(dataset, batch_size=config[\"batch_size\"], sampler=val_sampler)\n",
    "\n",
    "        # Reinitialize the model for each fold\n",
    "        model = CustomCNN(num_classes=len(dataset.classes)).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "        best_val_loss, patience_counter = float('inf'), 0\n",
    "        best_model_path = f'checkpoint_fold{fold}_best.pth'\n",
    "\n",
    "        for epoch in range(1, config[\"epochs\"] + 1):\n",
    "            print(f\"Epoch {epoch}/{config['epochs']}\")\n",
    "\n",
    "            train_loss, train_accuracy = train_epoch(model, train_loader, criterion, optimizer)\n",
    "            val_loss, val_accuracy = validate_epoch(model, val_loader, criterion)\n",
    "\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "            writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "            writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "            writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "            writer.add_scalar('Accuracy/val', val_accuracy, epoch)\n",
    "            writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "            # Update the learning rate based on validation loss\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            # Save the model if it has the best validation loss so far\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                print(f\"New best model found for fold {fold} at epoch {epoch}, saving model...\")\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                }, best_model_path)\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            # Early stopping\n",
    "            if patience_counter >= config[\"patience\"]:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fold_models(num_folds, model_class, num_classes, model_paths):\n",
    "    models = []\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        model = model_class(num_classes=num_classes).to(device)\n",
    "        checkpoint = torch.load(model_paths[fold - 1])\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        models.append(model)\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ensemble(models, image):\n",
    "    with torch.no_grad():\n",
    "        outputs = [model(image) for model in models]\n",
    "        avg_output = torch.mean(torch.stack(outputs), dim=0)\n",
    "        _, predicted = torch.max(avg_output, 1)\n",
    "    return predicted.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/4p37f261177fmjpv4kt7x33m0000gn/T/ipykernel_72603/2874168609.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_paths[fold - 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the image is: H2\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of FungiDataset to get the classes\n",
    "dataset = FungiDataset(config[\"base_dir\"], transform=get_transforms(), subset='train')\n",
    "num_classes = len(dataset.classes)\n",
    "\n",
    "# Define the absolute base path to where the checkpoints are saved\n",
    "base_model_path = \"/Users/saahil/Desktop/Coding_Projects/DL/MicroscopicFungi\"\n",
    "\n",
    "# Define the paths to the saved models for each fold using the absolute path\n",
    "model_paths = [os.path.join(base_model_path, f'checkpoint_fold{fold}_best.pth') for fold in range(1, config[\"num_folds\"] + 1)]\n",
    "\n",
    "# Load all the saved models\n",
    "models = load_fold_models(config[\"num_folds\"], CustomCNN, num_classes, model_paths)\n",
    "\n",
    "# Load and preprocess the image\n",
    "def preprocess_image(image_path, transform):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image=np.array(image))['image']\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    return image.to(device)\n",
    "\n",
    "# Single image path\n",
    "image_path = \"/Users/saahil/Desktop/Coding_Projects/DL/MicroscopicFungi/archive-2/test/H2/H2_1a_12.jpg.jpg\"\n",
    "image = preprocess_image(image_path, get_transforms())\n",
    "\n",
    "# Get the ensemble prediction\n",
    "predicted_class = predict_ensemble(models, image)\n",
    "print(f\"The predicted class for the image is: {dataset.classes[predicted_class]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
